\chapter{Introduction}
\label{chp:intro}

\hspace{0.1in}
\section{Motivation}
Recommendation systems have become extremely popular in recent years, typical recommendation system recommends items (movies, music, books, etc.) that users may be interested in. Collaborative filtering approaches build a model from users' past behavior to predict items which they may have an interest in. 
In real-world recommendation systems, the amount of users or items is huge. Users can only rate a small fraction of items, thus the user-item matrix is extremely sparse. What's more, sometimes we can't observe explicit ratings, only implicit behavior is provided(e.g. click, pageview and purchase). Such problem may lead to poor performance in CF models.

Recently, different transfer learning methods have been developed to improve the performance of the model.In \cite{/ijcai/libin09, /icml/libin09}, they use a rating-pattern sharing scheme to share user-item ratings pattern across different domains. In \cite{/aaai/WPan12, Pan:2011:TLP:2283696.2283784}, implicit dataset is available, knowledge is transferred via latent-feature sharing. In \cite{/uai/ZhangCY10, DBLP:conf/aaai/EldardiryN11} they try to exploit correlations among multiple domains.

However, most of the methods are developed for rating prediction problems. For example, in a music \& book rating website, a user can have high or low rating for an album and the rating is usually trustful and informative. Thus can be used to recommend books to the same user. But in a website where only implicit feedback is available(e.g advertisement click), the behavior can be much more noisy and with less information. To achieve better performance, we must transfer more knowledge from source domain while be very careful about the noise.

Some works have been done on solving one-class recommendation problem \cite{4781121, 4781145, DBLP:dblp_conf/aaai/LinKH14}. They all model the frequency of actions by a confidence matrix. For example, if you clicked an item A for 10 times, item B for 1 time. It's confident that you like A, but doubtful that you like B. On the other side, if you are an experienced user and you didn't click a popular item A, then it's highly possible that you didn't like A. But these works only explore the original user-item matrix, in real-world there are many other useful information which can be used to improve performance.

We collect several users' clicking and purchasing behaviors from an online shopping site. After taking analysis carefully, we find that users' behaviors on clicking and purchasing are similar, but not the same. Based on that, we develop a matrix tri-factorization method(TRIMF) to transfer knowledge from side to side. TRIMF can be used to achieve different goals, (e.g. optimize for click-through-rate/conversion-rate).

Further, to make the method online, we develop a clustering-based matrix factorization method(CBMF) using Hadoop. CBMF collects all kinds of user data and convert them into a single matrix per task. For cold-start users, a weighted recommendation from their neighbors will be provided. While for registered users, results is mixed with direct matrix factorization.

\hspace{0.1in}
\section{Contributions}

Our main contributions are summarized as follows:

\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item First, we find that in implicit datasets, more data must be shared to achieve better performance. To transfer more knowledge, a matrix tri-factorization method is proposed to transfer knowledge from user side and item side(TRIMF).
\item Second, implicit datasets can consist many noises. To transfer trustful knowledge, we develop a clustering-pattern transfer function. For each task, we provide a clustering pattern mapping function, which only does cluster-level transformation. Thus we can share knowledge more accurately without losing too much information.
\item Third, we propose a modified version of TRIMF(CBMF) which can be used for large scale recommendation. It is used in an Internet company, and it's performance is among the best in all online algorithms.
\end{itemize}

\hspace{0.1in}
\section{Thesis Outline}

The rest of the thesis is organized as follows: We first provide the background of the research on Collaborative Filtering, Matrix Factorization and Transfer Learning in Chapter \ref{chp:bg}. Then, we discuss the technique details of the proposed matrix tri-factorization method(TRIMF) and experiments on real-world datasets in Chapter \ref{chp:trimf}. We present details of our proposed CBMF framework and experiments in an online website in Chapter \ref{chp:cbmf} . Finally, we share our thoughts of possible future work and conclude the thesis in Chapter \ref{chp:conclusion}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

