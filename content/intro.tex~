\chapter{Introduction}
\label{chp:intro}

\hspace{0.1in}
\section{Motivation}
Recommendation systems have become extremely common in recent years, typical recommendation system recommends items (movies, music, books, etc.) that users may be interested in. Collaborative filtering approaches build a model from users' past behavior to predict items that the user may have an interest in. 
In real-world recommendation systems, users and items are all very large, so users can only rate a small fraction of items. Thus, the user-item matrix can be extremely sparse. What's more, sometimes we can't observe explicit ratings, only implicit feedback is provided(e.g click, pageview and purchase). Such problem may lead to poor performance in CF models.

Recently, different transfer learning methods have been developed to improve the performance of the model.In \cite{/ijcai/libin09, /icml/libin09}, they use a rating-pattern sharing scheme to share user-item ratings pattern across different domains. In \cite{/aaai/WPan12, Pan:2011:TLP:2283696.2283784}, implicit feedback data is available, knowledge is transferred via latent-feature sharing. In \cite{/uai/ZhangCY10, DBLP:conf/aaai/EldardiryN11} they try to exploit correlations among multiple domains.
However, most of the methods are develeoped for rating prediction problems. For example, in a music \& book rating website, a user can have high or low rating for an album. The ratings are usually trustful, thus can be used to recommend books to the same users. But in a website where only implicit feedback is available(e.g advertisement), the behavior can be much more noisy and with less information. So to acheive better performance, we much transfer more knowledge from source domain while be very careful about the noise.

Some works have been done on solving one-class recommendation problem \cite{4781121, 4781145}. They all try to model the freqency of actions by a confidence matrix. For example, if you clicked an item A for 10 times, item B for 1 times. It's more confident that you like A, but not quite sure that you like B. On the other side, if you are a heavy user and you didn't click a popular item A, then it's highly possible that you don't like A. But these works only explore the original matrix, in real-world there are many other useful informations which can be used to improve performance.

We collect several users' clicking and purchasing behaviors from two online shopping site. After taking careful analysis, we find that users' behaviors on clicking and purchasing are similar, but not the same. Based on that, we develop a matrix tri-factorization method(TRIMF) to transfer knowledge from side to side. TRIMF can be used to achieve different goals, (e.g optimize for Ctr(Cvr)).

Further, to make the method online, we develeop a clustering-based matrix factorization method(CBMF) using hadoop. CBMF collect all kinds of user data and convert them into a single matrix per task. For cold-start users, a weighted recommendation from their neighbors will be provided. While for registered users, results are mixed with direct matrix factorization and CBMF.

\hspace{0.1in}
\section{Contributions}

Our main contributions are summarized as follows:

\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item First, we find that selecting consistent auxiliary data for the target domain is important for the cross-domain collaborative filtering, while the consistency between source and target domains is influenced by multiple factors. To describe these factors, we propose a novel  criterion to measure the consistency between source and target domains, based on both empirical error and its variance.
\item Second, we propose a {\em selective} transfer learning framework for collaborative filtering - an extension of the boosting-based transfer learning algorithm that takes the above criterion into consideration while performing knowledge transfer, so that the sparseness issue in the CF problems can be better tackled.
\item Third, the proposed framework is general, where different base models can be embedded. We propose an implementation based on Gaussian probability latent semantic analysis, which demonstrates the proposed framework can solve the sparseness problem on various real-world applications.
\item Fourth, we investigate the distributed techniques and designed our proposed STLCF to well fit into them. Therefore, our work can be classified as an instance of large scale transfer learning. The parallel implementation demonstrates the power to handle the real-world tasks.
\end{itemize}

\hspace{0.1in}
\section{Thesis Outline}

The rest of the thesis is organized as follows: we first provide the background of the research on Selective Transfer Learning for Cross Domain Recommendation, together with a very brief survey of the field in Chapter \ref{chp:bg}. Then, we discuss the technique grounds of the proposed framework in Chapter \ref{chp:gplsa}. We present the details of our proposed STLCF framework in Chapter \ref{chp:STLCF} and the experiments in Chapter \ref{chp:exp}. Finally, we share our thoughts of possible future work and conclude the thesis in Chapter \ref{chp:conclusion}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

