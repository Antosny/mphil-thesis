\chapter{Introduction}
\label{chp:intro}

\hspace{0.1in}
\section{Motivation}
Recommendation systems have become extremely popular in recent years. Typical recommendation systems recommend items (movies, music, books, etc.) that users may be interested in. Collaborative filtering approaches build a model from users’ past behavior to predict items they may have an interest in. In real-world recommendation systems, the number of users or items is huge. Users can only rate a small fraction of items, thus the user-item matrix is extremely sparse. What is more, we sometimes cannot observe explicit ratings as only implicit behavior is provided (e.g. click, pageview and purchase). Such a problem may lead to poor performance in CF models.

Different transfer learning methods have been developed recently to improve the performance of the model.In \cite{/ijcai/libin09, /icml/libin09}, they use a rating-pattern sharing scheme to share user-item rating patterns across different domains. In \cite{/aaai/WPan12, Pan:2011:TLP:2283696.2283784}, an implicit dataset is available and knowledge is transferred via latent-feature sharing. In \cite{/uai/ZhangCY10, DBLP:conf/aaai/EldardiryN11} the authors try to exploit correlations among multiple domains.
However, most of the methods are developed for rating prediction problems. For example, in a music \& book rating website, a user can have high or low rating for an album and the rating is usually trustworthy and informative. It can thus be used to recommend books to the same user. However, in a website where only implicit feedback is available (e.g. advertisement clicks), the behavior can be much more noisy and with less information. To achieve better performance, we must transfer more knowledge from source domain while being very careful about the noise. 

Some works have been done on solving one-class recommendation problem \cite{4781121, 4781145, DBLP:dblp_conf/aaai/LinKH14}. They all model the frequency of actions by a confidence matrix. For example, if you clicked on item A 10 times, item B one time, there can be certainty that you like A, but uncertainty of whether you like B. On the other side, if you are an experienced user and you did not click a popular item A, then it is highly probable that you did not like A. However, these works only explore the original user-item matrix, in the real-world there are enormous amounts of other useful information which can be used to improve performance.

We collect several users’ clicking and purchasing behaviors from an online shopping site. After careful analysis, we find that users’ clicking and purchasing behaviors may be similar, but not the same. Based on that, we develop a matrix tri-factorization method (TRIMF) to transfer knowledge from side to side. TRIMF can be used to achieve different goals, (e.g. optimize the click-through-rate/conversion-rate).

Further, to make the method scalable and able to put online, we develop a clustering-based matrix factorization method (CBMF) using Hadoop. CBMF collects all kinds of user data and convert them into a single matrix per task. For cold-start users, a weighted recommendation from their neighbors is provided, while for registered users results are mixed with direct matrix factorization.

\hspace{0.1in}
\section{Contributions}

Our main contributions are summarized as follows:

\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item First, we find that in implicit datasets, more data must be shared to achieve better performance. To transfer more knowledge, a matrix tri-factorization method is proposed to transfer knowledge from the user side and item side (TRIMF).
\item Second, implicit datasets consist too much noise. To transfer trustful knowledge, we develop a clustering-pattern transfer function. For each task, we provide a clustering pattern mapping function, which only does cluster-level transformation. Thus we can share knowledge more accurately without losing too much information.
\item Third, we propose a modified version of TRIMF (CBMF) which can be used for large scale recommendation. It is used in an Internet company, and it's performance is among the best of all online algorithms.
\end{itemize}

\hspace{0.1in}
\section{Thesis Outline}

The rest of the thesis is organized as follows: We first provide the background of the research on Collaborative Filtering, Matrix Factorization and Transfer Learning in Chapter \ref{chp:bg}. Then, we discuss the technique of the proposed matrix tri-factorization method(TRIMF) in detail in Chapter \ref{chp:trimf}. We present details of our proposed CBMF framework in Chapter \ref{chp:cbmf} . We perform two experiments, offline and online, in Chapter \ref{chp:exp}. Finally, we share our thoughts on possible future work and conclude the thesis in Chapter \ref{chp:conclusion}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

